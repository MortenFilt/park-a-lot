{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring images with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Mikke\\\\OneDrive\\\\Skole\\\\UNI\\\\7. semester\\\\BAC\\\\Image Detection'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing intial packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from skimage.filters import threshold_local\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\\.ipynb_checkpoints\n",
      ".\\Letters\n",
      ".\\Letters\\emnist_source_files\n",
      ".\\License Plates\n",
      ".\\License Plates\\annotations\n",
      ".\\License Plates\\images\n",
      ".\\Size Recognition\n",
      ".\\__pycache__\n"
     ]
    }
   ],
   "source": [
    "# Check content of current dir\n",
    "for dirname, _, filenames in os.walk('.'):\n",
    "    print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display first image in '.\\License Plates\\images' with Matplotlib\n",
    "\n",
    "# Load as pixel array\n",
    "test_image = cv2.imread('.\\License Plates\\images\\*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-0dd3f5772261>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Display pixel array as image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2643\u001b[0m         \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deprecated_parameter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2644\u001b[0m         resample=None, url=None, *, data=None, **kwargs):\n\u001b[1;32m-> 2645\u001b[1;33m     __ret = gca().imshow(\n\u001b[0m\u001b[0;32m   2646\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1563\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1564\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1565\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    356\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    356\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5626\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5628\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    691\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[0;32m    692\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m--> 693\u001b[1;33m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0m\u001b[0;32m    694\u001b[0m                             \"float\".format(self._A.dtype))\n\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display pixel array as image\n",
    "plt.imshow(test_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Jupyter layers image planes in BGR instead of RGB \n",
    "# it needs to be converted to RGB\n",
    "# This should also be made into a method\n",
    "\n",
    "test_image_rgb = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(test_image_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to isolate the licensplate into a new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This \"cleanup\" should be in its own method \n",
    "# since it needs to be done in all images\n",
    "\n",
    "# Convert to grey scale - good for analysing\n",
    "gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "gray_image_rgb = cv2.cvtColor(gray_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(gray_image_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blur to reduce noise - good for analysing contours\n",
    "gray_image_blurred = cv2.bilateralFilter(gray_image, 11, 17, 17)\n",
    "\n",
    "gray_image_blurred_rgb = cv2.cvtColor(gray_image_blurred, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(gray_image_blurred_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge detection /w Canny Edge Method\n",
    "# OpenCv has it build in so we'll use that\n",
    "# This is how it works:\n",
    "# https://docs.opencv.org/master/da/d22/tutorial_py_canny.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_edged_30_200_L1 = cv2.Canny(gray_image_blurred, 30, 200)\n",
    "\n",
    "img_to_show = cv2.cvtColor(test_image_edged_30_200_L1, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_edged_100_200_L1 = cv2.Canny(gray_image_blurred, 100, 200)\n",
    "\n",
    "img_to_show = cv2.cvtColor(test_image_edged_100_200_L1, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_edged_150_200_L1 = cv2.Canny(gray_image_blurred, 150, 200)\n",
    "\n",
    "img_to_show = cv2.cvtColor(test_image_edged_150_200_L1, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since images will be of varrying quality canny edge detection will we done with a rather low threshold for the hysteresis procedure, to ensure high realiability.  (30, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for contours \n",
    "contours = cv2.findContours(test_image_edged_30_200_L1,\n",
    "                        cv2.RETR_TREE,\n",
    "                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "# Sort detected contours from big to small\n",
    "contours = imutils.grab_contours(contours)\n",
    "contours = sorted(contours, key = cv2.contourArea, reverse = True)[:10]\n",
    "screenCnt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for rectangular contour with a closed figure.\n",
    "for contour in contours:\n",
    "    peri = cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, 0.018 * peri, True)\n",
    "    \n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask everything except the license plate\n",
    "mask = np.zeros(test_image_edged_30_200_L1.shape, np.uint8)\n",
    "new_image = cv2.drawContours(mask, [screenCnt], 0 , 255, -1, )\n",
    "new_image = cv2.bitwise_and(gray_image_blurred, gray_image_blurred, mask=mask)\n",
    "\n",
    "img_to_show = cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new cropped image only with the licensplate\n",
    "(x, y) = np.where(mask == 255)\n",
    "(topx, topy) = (np.min(x), np.min(y))\n",
    "(bottomx, bottomy) = (np.max(x), np.max(y))\n",
    "cropped = test_image[topx:bottomx+1, topy:bottomy+1]\n",
    "\n",
    "img_to_show = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the Value component from the HSV color space and apply adaptive thresholding\n",
    "# to reveal the characters on the license plate\n",
    "V = cv2.split(cv2.cvtColor(cropped, cv2.COLOR_BGR2HSV))[2]\n",
    "T = cv2.threshold(V, 180, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "thresh = (V > T).astype(\"uint8\") * 255\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "# resize the license plate region to a canonical size\n",
    "cropped = imutils.resize(cropped, width=400)\n",
    "thresh = imutils.resize(thresh, width=400)\n",
    "\n",
    "img_to_show = cv2.cvtColor(T, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## contours sorting method\n",
    "def sort_contours(contours, reverse=False):\n",
    "    i = 0\n",
    "    bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "    (contours, bounding_boxes) = zip(*sorted(zip(contours, bounding_boxes),\n",
    "                                            key=lambda b: b[1][i], reverse=reverse))\n",
    "    return contours\n",
    "\n",
    "contours, _ = cv2.findContours(T, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "width, height = T.shape\n",
    "dimension = (height, width)\n",
    "\n",
    "cropped = cv2.resize(cropped, dimension ,interpolation = cv2.INTER_AREA)\n",
    "\n",
    "test_roi = cropped.copy()\n",
    "crop_characters = []\n",
    "\n",
    "digit_w, digit_h = 30, 60\n",
    "\n",
    "for contour in sort_contours(contours):\n",
    "    (x, y, w, h) = cv2.boundingRect(contour)\n",
    "    aspect_ratio = w / float(h)\n",
    "    solidity = cv2.contourArea(contour) / float(w * h)\n",
    "    height_ratio = h / float(cropped.shape[0])\n",
    "    \n",
    "    keep_aspect_ratio = aspect_ratio < 1.0\n",
    "    keep_solidity = solidity > 0.15\n",
    "    keep_height = height_ratio > 0.2 and height_ratio < 0.95\n",
    "    \n",
    "    if keep_aspect_ratio and keep_solidity and keep_height:\n",
    "        test_roi = cv2.rectangle(test_roi, (x, y), (x + w, y + h), (0, 255, 0), 1) \n",
    "        curr_num = T[y:y+h,x:x+w]\n",
    "        curr_num = cv2.resize(curr_num, dsize=(digit_w, digit_h))\n",
    "        _, curr_num = cv2.threshold(curr_num, 220, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        crop_characters.append(curr_num)\n",
    "        \n",
    "        \n",
    "print(\"Detect {} letters...\".format(len(crop_characters)))\n",
    "img_to_show = cv2.cvtColor(test_roi, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(crop_characters)):\n",
    "    img_to_show = cv2.cvtColor(crop_characters[i], cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_to_show)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing for our dataset\n",
    "Siden ovenstående billeder ikke passer særligt godt til vores datasæt, der er brugt til at træne modellen, skal dataet omformateres en smule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First try to resize without changing any proportions\n",
    "img_to_show = cv2.cvtColor(crop_characters[3], cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()\n",
    "print('Resize to 28x28')\n",
    "resized_char = cv2.resize(crop_characters[3], dsize=(28, 28))\n",
    "img_to_show = cv2.cvtColor(resized_char, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultatet ser lovende ud, men lad os se om det ikke kan gøres bedre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_char = cv2.copyMakeBorder(crop_characters[3], 4, 4, 19, 19, cv2.BORDER_CONSTANT, None, [0, 0, 0])\n",
    "img_to_show = cv2.cvtColor(new_char, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_char = cv2.resize(new_char, dsize=(28, 28))\n",
    "img_to_show = cv2.cvtColor(resized_char, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
